{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "959c59e1",
   "metadata": {},
   "source": [
    "# SARSA CartPole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6acee33",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "import time\n",
    "import random\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "GAMMA = 0.99\n",
    "\n",
    "# SARSA hyperparameters\n",
    "N_EPISODES = 500\n",
    "MAX_STEPS = 500\n",
    "ALPHA = 0.1\n",
    "EPS_START = 1.0\n",
    "EPS_END = 0.05\n",
    "\n",
    "SEED_LIST = list(range(1, 11))  # seeds\n",
    "BASE_B = 4                       # base grid size; n_bins = [b, b, 2b, 2b]\n",
    "\n",
    "print(\"Seed list:\", SEED_LIST)\n",
    "print(\"Base grid size:\", BASE_B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299bba67",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------\n",
    "# Helpers: seeding, discretization\n",
    "# ------------------------------\n",
    "def set_seed(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "TERMINAL = (-1, -1, -1, -1)\n",
    "\n",
    "def make_n_bins(b: int):\n",
    "    \"\"\"Map scalar grid size to per-dimension bins (same pattern as VI/PI).\"\"\"\n",
    "    return [b, b, 2 * b, 2 * b]\n",
    "\n",
    "def build_states(n_bins_vec):\n",
    "    states = list(product(*(range(n) for n in n_bins_vec)))\n",
    "    states.append(TERMINAL)\n",
    "    return states\n",
    "\n",
    "def get_cartpole_bounds(env):\n",
    "    low = env.observation_space.low.astype(np.float64).copy()\n",
    "    high = env.observation_space.high.astype(np.float64).copy()\n",
    "    # Cap unbounded dimensions\n",
    "    low[1] = -3.0\n",
    "    high[1] = 3.0\n",
    "    low[3] = -3.0\n",
    "    high[3] = 3.0\n",
    "    return low, high\n",
    "\n",
    "def discretize_state(obs, n_bins_vec, state_low, state_high):\n",
    "    ratios = (obs - state_low) / (state_high - state_low)\n",
    "    ratios = np.clip(ratios, 0.0, 0.9999)\n",
    "    bins = [int(r * n) for r, n in zip(ratios, n_bins_vec)]\n",
    "    return tuple(bins)\n",
    "\n",
    "# ------------------------------\n",
    "# SARSA algorithm\n",
    "# ------------------------------\n",
    "def epsilon_greedy(Q, state_idx, eps, n_actions=2):\n",
    "    if np.random.rand() < eps:\n",
    "        return np.random.randint(n_actions)\n",
    "    else:\n",
    "        return int(np.argmax(Q[state_idx]))\n",
    "\n",
    "def sarsa_train(env,\n",
    "                n_bins_vec,\n",
    "                state_low,\n",
    "                state_high,\n",
    "                states,\n",
    "                state_to_idx,\n",
    "                n_episodes=N_EPISODES,\n",
    "                max_steps=MAX_STEPS,\n",
    "                alpha=ALPHA,\n",
    "                gamma=GAMMA,\n",
    "                eps_start=EPS_START,\n",
    "                eps_end=EPS_END):\n",
    "    \"\"\"\n",
    "    Tabular SARSA on discretized CartPole.\n",
    "    Returns:\n",
    "        Q:      (n_states, n_actions)\n",
    "        returns_per_episode: length n_episodes\n",
    "        deltaQ_per_episode:  length n_episodes (max |ΔQ| in that episode)\n",
    "    \"\"\"\n",
    "    n_actions = 2\n",
    "    n_states = len(state_to_idx)\n",
    "    Q = np.zeros((n_states, n_actions), dtype=np.float64)\n",
    "\n",
    "    returns = np.zeros(n_episodes, dtype=np.float64)\n",
    "    delta_Q = np.zeros(n_episodes, dtype=np.float64)\n",
    "\n",
    "    for ep in range(n_episodes):\n",
    "        # Linear epsilon decay\n",
    "        frac = ep / max(1, n_episodes - 1)\n",
    "        eps = eps_start + frac * (eps_end - eps_start)\n",
    "\n",
    "        obs, _ = env.reset()\n",
    "        s = discretize_state(obs, n_bins_vec, state_low, state_high)\n",
    "        s_idx = state_to_idx[s]\n",
    "\n",
    "        a = epsilon_greedy(Q, s_idx, eps, n_actions=n_actions)\n",
    "\n",
    "        total_r = 0.0\n",
    "        max_delta_this_ep = 0.0\n",
    "\n",
    "        for t in range(max_steps):\n",
    "            next_obs, r, terminated, truncated, _ = env.step(a)\n",
    "            done = terminated or truncated\n",
    "            total_r += r\n",
    "\n",
    "            if done:\n",
    "                target = r  # no next Q term\n",
    "                s_next_idx = None\n",
    "                a_next = None\n",
    "            else:\n",
    "                s_next = discretize_state(next_obs, n_bins_vec, state_low, state_high)\n",
    "                s_next_idx = state_to_idx[s_next]\n",
    "                a_next = epsilon_greedy(Q, s_next_idx, eps, n_actions=n_actions)\n",
    "                target = r + gamma * Q[s_next_idx, a_next]\n",
    "\n",
    "            old_q = Q[s_idx, a]\n",
    "            Q[s_idx, a] = old_q + alpha * (target - old_q)\n",
    "            delta = abs(Q[s_idx, a] - old_q)\n",
    "            if delta > max_delta_this_ep:\n",
    "                max_delta_this_ep = delta\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            # move on\n",
    "            obs = next_obs\n",
    "            s_idx = s_next_idx\n",
    "            a = a_next\n",
    "\n",
    "        returns[ep] = total_r\n",
    "        delta_Q[ep] = max_delta_this_ep\n",
    "\n",
    "    return Q, returns, delta_Q\n",
    "\n",
    "# ------------------------------\n",
    "# Evaluation helper (greedy policy)\n",
    "# ------------------------------\n",
    "def q_to_policy(Q, states, state_to_idx):\n",
    "    policy = {}\n",
    "    for s in states:\n",
    "        if s == TERMINAL:\n",
    "            continue\n",
    "        idx = state_to_idx[s]\n",
    "        policy[s] = int(np.argmax(Q[idx]))\n",
    "    return policy\n",
    "\n",
    "def evaluate_policy(env,\n",
    "                    policy,\n",
    "                    n_bins_vec,\n",
    "                    state_low,\n",
    "                    state_high,\n",
    "                    n_episodes=50,\n",
    "                    max_steps=MAX_STEPS):\n",
    "    returns = []\n",
    "    for _ in range(n_episodes):\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        total_r = 0.0\n",
    "        steps = 0\n",
    "        while not done and steps < max_steps:\n",
    "            s = discretize_state(obs, n_bins_vec, state_low, state_high)\n",
    "            a = policy.get(s, 0)\n",
    "            obs, r, terminated, truncated, _ = env.step(a)\n",
    "            done = terminated or truncated\n",
    "            total_r += r\n",
    "            steps += 1\n",
    "        returns.append(total_r)\n",
    "    return np.array(returns, dtype=np.float64)\n",
    "\n",
    "# ------------------------------\n",
    "# Plot helpers\n",
    "# ------------------------------\n",
    "def plot_mean_iqr(curves, title, ylabel, filename,\n",
    "                  x_label=\"Episode\", ylog=False):\n",
    "    \"\"\"\n",
    "    curves: list of 1D arrays, one per seed.\n",
    "    Plots mean with IQR band.\n",
    "    \"\"\"\n",
    "    if len(curves) == 0:\n",
    "        return\n",
    "\n",
    "    max_len = max(len(c) for c in curves)\n",
    "    mat = np.full((len(curves), max_len), np.nan)\n",
    "    for i, c in enumerate(curves):\n",
    "        mat[i, :len(c)] = c\n",
    "\n",
    "    mean = np.nanmean(mat, axis=0)\n",
    "    q25 = np.nanpercentile(mat, 25, axis=0)\n",
    "    q75 = np.nanpercentile(mat, 75, axis=0)\n",
    "    xs = np.arange(max_len)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(xs, mean, label=\"mean\")\n",
    "    plt.fill_between(xs, q25, q75, alpha=0.3, label=\"IQR\")\n",
    "    if ylog:\n",
    "        plt.yscale(\"log\")\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.4)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "def plot_mean_std_over_seeds(returns_per_seed, title, filename):\n",
    "    \"\"\"\n",
    "    returns_per_seed: list of 1D arrays (n_episodes),\n",
    "    Build mean ± std across seeds at each episode.\n",
    "    \"\"\"\n",
    "    if len(returns_per_seed) == 0:\n",
    "        return\n",
    "\n",
    "    max_len = max(len(c) for c in returns_per_seed)\n",
    "    mat = np.full((len(returns_per_seed), max_len), np.nan)\n",
    "    for i, c in enumerate(returns_per_seed):\n",
    "        mat[i, :len(c)] = c\n",
    "\n",
    "    mean = np.nanmean(mat, axis=0)\n",
    "    std = np.nanstd(mat, axis=0)\n",
    "    xs = np.arange(max_len)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(xs, mean, label=\"mean return\")\n",
    "    plt.fill_between(xs, mean - std, mean + std, alpha=0.3, label=\"±1 std\")\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Return\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.4)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "# ------------------------------\n",
    "# Main experiment\n",
    "# ------------------------------\n",
    "actions = [0, 1]\n",
    "b = BASE_B\n",
    "n_bins_vec = make_n_bins(b)\n",
    "states = build_states(n_bins_vec)\n",
    "\n",
    "# mapping from state -> index (exclude TERMINAL from Q)\n",
    "state_to_idx = {s: i for i, s in enumerate(states) if s != TERMINAL}\n",
    "\n",
    "all_returns = []      # list of (N_EPISODES,) per seed\n",
    "all_deltaQ = []       # list of (N_EPISODES,) per seed\n",
    "eval_returns = []     # scalar mean eval return per seed\n",
    "wallclock_per_seed = []\n",
    "\n",
    "total_wallclock = 0.0\n",
    "\n",
    "for seed in SEED_LIST:\n",
    "    print(f\"Running SARSA for seed {seed}\")\n",
    "    set_seed(seed)\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "    state_low, state_high = get_cartpole_bounds(env)\n",
    "\n",
    "    t0 = time.time()\n",
    "    Q, returns_ep, deltaQ_ep = sarsa_train(\n",
    "        env,\n",
    "        n_bins_vec,\n",
    "        state_low,\n",
    "        state_high,\n",
    "        states,\n",
    "        state_to_idx,\n",
    "        n_episodes=N_EPISODES,\n",
    "        max_steps=MAX_STEPS,\n",
    "        alpha=ALPHA,\n",
    "        gamma=GAMMA,\n",
    "        eps_start=EPS_START,\n",
    "        eps_end=EPS_END,\n",
    "    )\n",
    "    elapsed = time.time() - t0\n",
    "    total_wallclock += elapsed\n",
    "    wallclock_per_seed.append(elapsed)\n",
    "\n",
    "    all_returns.append(returns_ep)\n",
    "    all_deltaQ.append(deltaQ_ep)\n",
    "\n",
    "    # Evaluate final greedy policy (optional, useful for checking stability)\n",
    "    policy = q_to_policy(Q, states, state_to_idx)\n",
    "    eval_ret = evaluate_policy(\n",
    "        env,\n",
    "        policy,\n",
    "        n_bins_vec,\n",
    "        state_low,\n",
    "        state_high,\n",
    "        n_episodes=50,\n",
    "        max_steps=MAX_STEPS,\n",
    "    )\n",
    "    eval_returns.append(eval_ret.mean())\n",
    "\n",
    "    env.close()\n",
    "\n",
    "print(f\"\\nTotal SARSA wall-clock over all seeds: {total_wallclock:.2f} s\")\n",
    "\n",
    "# ------------------------------\n",
    "# 1) Learning curve: return vs episodes\n",
    "# ------------------------------\n",
    "plot_mean_iqr(\n",
    "    all_returns,\n",
    "    title=f\"SARSA CartPole — Learning Curve (b={b})\",\n",
    "    ylabel=\"Return per episode\",\n",
    "    filename=f\"cartpole_sarsa_learning_curve_b{b}.pdf\",\n",
    "    x_label=\"Episode\",\n",
    "    ylog=False,\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 2) ΔQ vs episodes (max Q-table change)\n",
    "# ------------------------------\n",
    "plot_mean_iqr(\n",
    "    all_deltaQ,\n",
    "    title=f\"SARSA CartPole — ΔQ per Episode (b={b})\",\n",
    "    ylabel=\"Max |ΔQ| in episode\",\n",
    "    filename=f\"cartpole_sarsa_deltaQ_b{b}.pdf\",\n",
    "    x_label=\"Episode\",\n",
    "    ylog=True,  # often nice to see convergence on log scale\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 3) Stability plot: mean ± std of return across seeds\n",
    "#    (here: return vs episodes with band = std across seeds)\n",
    "# ------------------------------\n",
    "plot_mean_std_over_seeds(\n",
    "    all_returns,\n",
    "    title=f\"SARSA CartPole — Stability Across Seeds (b={b})\",\n",
    "    filename=f\"cartpole_sarsa_stability_b{b}.pdf\",\n",
    ")\n",
    "\n",
    "# If you also want a single-point stability summary (final performance):\n",
    "eval_returns = np.array(eval_returns, dtype=np.float64)\n",
    "print(\"\\nEvaluation returns (greedy policy) per seed:\")\n",
    "for seed, r in zip(SEED_LIST, eval_returns):\n",
    "    print(f\"  Seed {seed}: mean return = {r:.2f}\")\n",
    "print(f\"Overall mean ± std: {eval_returns.mean():.2f} ± {eval_returns.std():.2f}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 4) Wall-clock time vs seed\n",
    "# ------------------------------\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(SEED_LIST, wallclock_per_seed, \"-o\")\n",
    "plt.xlabel(\"Seed\")\n",
    "plt.ylabel(\"Wall-clock time per seed (s)\")\n",
    "plt.title(f\"SARSA CartPole — Wall-clock vs Seed (b={b})\")\n",
    "plt.grid(True, alpha=0.4)\n",
    "plt.xticks(SEED_LIST)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"cartpole_sarsa_wallclock_vs_seed_b{b}.pdf\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDone. SARSA CartPole figures saved as:\")\n",
    "print(f\"  - cartpole_sarsa_learning_curve_b{b}.pdf\")\n",
    "print(f\"  - cartpole_sarsa_deltaQ_b{b}.pdf\")\n",
    "print(f\"  - cartpole_sarsa_stability_b{b}.pdf\")\n",
    "print(f\"  - cartpole_sarsa_wallclock_vs_seed_b{b}.pdf\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sl_report_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
